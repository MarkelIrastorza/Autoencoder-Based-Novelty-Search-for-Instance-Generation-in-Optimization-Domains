{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12971290,"sourceType":"datasetVersion","datasetId":8209795}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"AUTOENCODER-BASED NOVELTY SEARCH","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport math\nfrom itertools import permutations\nfrom google.colab import files\nimport zipfile\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport shutil\nfrom google.colab import files\nimport glob\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"10FWNLT06Ask","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:32.314642Z","iopub.execute_input":"2025-09-05T11:34:32.315010Z","iopub.status.idle":"2025-09-05T11:34:32.320991Z","shell.execute_reply.started":"2025-09-05T11:34:32.314986Z","shell.execute_reply":"2025-09-05T11:34:32.319939Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"Set seed for reproducibility","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef set_global_seed(seed=42):\n    random.seed(seed)\n\n    np.random.seed(seed)\n\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # Para múltiples GPUs\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.use_deterministic_algorithms(True)\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n\nset_global_seed(42)\n","metadata":{"id":"4wSaAcrZO7Cn","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:32.322473Z","iopub.execute_input":"2025-09-05T11:34:32.323451Z","iopub.status.idle":"2025-09-05T11:34:32.344235Z","shell.execute_reply.started":"2025-09-05T11:34:32.323416Z","shell.execute_reply":"2025-09-05T11:34:32.343385Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"Load instances","metadata":{}},{"cell_type":"code","source":"lolib = np.load('/kaggle/input/benchmark-instances/LOLIB_instances.npy')\nprint(lolib.shape)\nrandom_instances = np.load('/kaggle/input/benchmark-instances/random_instances.npy')\nprint(random_instances.shape)\nall_instances = np.load('/kaggle/input/benchmark-instances/benchmark_instances.npy')\nprint(all_instances.shape)\ntrain_3, test_3 = train_test_split(all_instances, test_size=0.2, random_state=42)\ntrain = train_3\nvalidation = test_3\ntest = test_3\nset_global_seed(42)\nprint(train.shape)","metadata":{"id":"Ln8GO3q_1inU","outputId":"96bb152a-ac2c-4ff5-b1fe-e7f72410e61a","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:32.345403Z","iopub.execute_input":"2025-09-05T11:34:32.345654Z","iopub.status.idle":"2025-09-05T11:34:32.393980Z","shell.execute_reply.started":"2025-09-05T11:34:32.345636Z","shell.execute_reply":"2025-09-05T11:34:32.393110Z"}},"outputs":[{"name":"stdout","text":"(3188, 20, 20)\n(1500, 20, 20)\n(4688, 20, 20)\n(3750, 20, 20)\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"Define and train the autoencoder","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Autoencoder(nn.Module):\n    def __init__(self, input_dim, latent_dim, hidden_dim=80):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, latent_dim),\n            nn.Tanh()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        z = self.encoder(x)\n        out = self.decoder(z)\n        return out\n\ndef ae_loss(recon_x, x):\n    return F.mse_loss(recon_x, x, reduction='mean')\n\ndef train_autoencoder(model, data, epochs=50, batch_size=64, lr=1e-3):\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    for epoch in range(epochs):\n        model.train()\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i+batch_size]\n            optimizer.zero_grad()\n            recon = model(batch)\n            loss = ae_loss(recon, batch)\n            loss.backward()\n            optimizer.step()\n\ndef get_ae_latents(model, data, batch_size=64):\n    model.eval()\n    latents = []\n    with torch.no_grad():\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i+batch_size]\n            z = model.encoder(batch)\n            latents.append(z)\n    return torch.cat(latents, dim=0)\n\ndef train_autoencoder_from_matrices(matrix_data, N, latent_dim=12, hidden_dim=80, epochs=15, batch_size=32, lr=1e-3):\n    matrix_array = np.array(matrix_data, dtype=np.float32)\n\n    # Mask to remove diagonal\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = matrix_array[:, mask]\n\n    # Flatten each masked matrix into a vector\n    flat_data = masked_data.reshape(masked_data.shape[0], -1)\n\n    # Convert to torch tensor\n    tensor_data = torch.tensor(flat_data, dtype=torch.float32)\n\n    # Define and train the model\n    input_dim = tensor_data.shape[1]\n    ae_model = Autoencoder(input_dim=input_dim, latent_dim=latent_dim, hidden_dim=hidden_dim)\n    train_autoencoder(ae_model, tensor_data, epochs=epochs, batch_size=batch_size, lr=lr)\n\n    # Get latent representation\n    latents = get_ae_latents(ae_model, tensor_data, batch_size=batch_size)\n\n    return latents, ae_model","metadata":{"id":"hK3hcrCw1su_","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:32.396001Z","iopub.execute_input":"2025-09-05T11:34:32.396265Z","iopub.status.idle":"2025-09-05T11:34:32.409397Z","shell.execute_reply.started":"2025-09-05T11:34:32.396244Z","shell.execute_reply":"2025-09-05T11:34:32.408451Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"set_global_seed(42)\nz, ae_model = train_autoencoder_from_matrices(train, 20)\nprint(np.max(z.numpy()))\nprint(np.mean(z.numpy()))","metadata":{"id":"IcogEkTXXxMt","outputId":"152b307c-88a2-4caa-a171-ea638fe250b2","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:32.410332Z","iopub.execute_input":"2025-09-05T11:34:32.410627Z","iopub.status.idle":"2025-09-05T11:34:36.414334Z","shell.execute_reply.started":"2025-09-05T11:34:32.410607Z","shell.execute_reply":"2025-09-05T11:34:36.413372Z"}},"outputs":[{"name":"stdout","text":"0.94285303\n-0.08491668\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"Define LS algorithms","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom numba import njit\n\n@njit\ndef profit_permutation(A, sigma):\n    total = 0.0\n    N = len(sigma)\n    for i in range(N):\n        for j in range(i + 1, N):\n            total += A[sigma[i], sigma[j]]\n    return total","metadata":{"id":"Dbzx2mjQ9OJz","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.415394Z","iopub.execute_input":"2025-09-05T11:34:36.415668Z","iopub.status.idle":"2025-09-05T11:34:36.421451Z","shell.execute_reply.started":"2025-09-05T11:34:36.415647Z","shell.execute_reply":"2025-09-05T11:34:36.420689Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"@njit\ndef two_opt_ls(A, rand_indices):\n    N = A.shape[0]\n    sigma = np.arange(N)\n    for i in range(N-1, 0, -1):\n        j = rand_indices[N - 1 - i]\n        sigma[i], sigma[j] = sigma[j], sigma[i]\n\n    a = profit_permutation(A, sigma)\n    improvement = True\n    while improvement:\n        improvement = False\n        for i in range(N):\n            for j in range(i+1, N):\n                sigma[i:j+1] = sigma[i:j+1][::-1]\n                b = profit_permutation(A, sigma)\n                if b > a:\n                    a = b\n                    improvement = True\n                    break\n                else:\n                    sigma[i:j+1] = sigma[i:j+1][::-1]\n            if improvement:\n                break\n\n    return sigma","metadata":{"id":"QuPmI5nC9tat","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.423208Z","iopub.execute_input":"2025-09-05T11:34:36.423798Z","iopub.status.idle":"2025-09-05T11:34:36.445122Z","shell.execute_reply.started":"2025-09-05T11:34:36.423765Z","shell.execute_reply":"2025-09-05T11:34:36.444307Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"@njit\ndef swap_ls(A, rand_indices):\n    N = A.shape[0]\n    sigma = np.arange(N)\n    for i in range(N - 1, 0, -1):\n        j = rand_indices[N - 1 - i]\n        sigma[i], sigma[j] = sigma[j], sigma[i]\n\n    current_profit = profit_permutation(A, sigma)\n    improvement = True\n    while improvement:\n        improvement = False\n        for i in range(N):\n            for j in range(i + 1, N):\n                sigma[i], sigma[j] = sigma[j], sigma[i]\n                new_profit = profit_permutation(A, sigma)\n\n                if new_profit > current_profit:\n                    current_profit = new_profit\n                    improvement = True\n                    break\n                else:\n                    sigma[i], sigma[j] = sigma[j], sigma[i]\n            if improvement:\n                break\n\n    return sigma","metadata":{"id":"y0BV5n8h9vxw","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.446600Z","iopub.execute_input":"2025-09-05T11:34:36.446939Z","iopub.status.idle":"2025-09-05T11:34:36.469804Z","shell.execute_reply.started":"2025-09-05T11:34:36.446910Z","shell.execute_reply":"2025-09-05T11:34:36.468717Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"@njit\ndef insert_ls(A, rand_indices):\n    N = A.shape[0]\n    sigma = np.arange(N)\n    for i in range(N-1, 0, -1):\n        j = rand_indices[N - 1 - i]\n        sigma[i], sigma[j] = sigma[j], sigma[i]\n\n    a = profit_permutation(A, sigma)\n    improvement = True\n    while improvement:\n        improvement = False\n        for i in range(N):\n            for j in range(N):\n                if i == j:\n                    continue\n                sigma_copy = sigma.copy()\n                temp = sigma_copy[i]\n                if i < j:\n                    for k in range(i, j):\n                        sigma_copy[k] = sigma_copy[k+1]\n                else:\n                    for k in range(i, j, -1):\n                        sigma_copy[k] = sigma_copy[k-1]\n                sigma_copy[j] = temp\n\n                b = profit_permutation(A, sigma_copy)\n                if b > a:\n                    sigma = sigma_copy\n                    a = b\n                    improvement = True\n                    break\n            if improvement:\n                break\n\n    return sigma","metadata":{"id":"Td65031s92Sr","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.472879Z","iopub.execute_input":"2025-09-05T11:34:36.473441Z","iopub.status.idle":"2025-09-05T11:34:36.494353Z","shell.execute_reply.started":"2025-09-05T11:34:36.473415Z","shell.execute_reply":"2025-09-05T11:34:36.493457Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"Define the NS algorithm and all the necessary functions","metadata":{}},{"cell_type":"code","source":"def profit(A, algorithm):\n    rand_indices = [np.random.randint(0, i+1) for i in range(N-1, 0, -1)]\n    sigma = np.array(algorithm(A, rand_indices))\n    idx = sigma.astype(int)\n\n    A_sub = A[np.ix_(idx, idx)]\n    total_sum = np.sum(np.triu(A_sub, k=1))\n    return total_sum","metadata":{"id":"8RBq-DJZ8ZTg","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.495165Z","iopub.execute_input":"2025-09-05T11:34:36.495407Z","iopub.status.idle":"2025-09-05T11:34:36.514913Z","shell.execute_reply.started":"2025-09-05T11:34:36.495388Z","shell.execute_reply":"2025-09-05T11:34:36.513825Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"def initialise(D, N):\n    # D[0] = population size, D[1] = values for uniform distribution (-D[1], D[1])\n    num_all_instances = D[0]\n    max_valor = D[1]\n\n    population = np.empty((num_all_instances, N, N))\n\n    for idx in range(num_all_instances):\n        A = np.random.uniform(-max_valor, max_valor, size=(N, N))\n        np.fill_diagonal(A, 0)\n        population[idx] = A\n    return population\n","metadata":{"id":"5_N4PMGs5393","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.515832Z","iopub.execute_input":"2025-09-05T11:34:36.516054Z","iopub.status.idle":"2025-09-05T11:34:36.539991Z","shell.execute_reply.started":"2025-09-05T11:34:36.516037Z","shell.execute_reply":"2025-09-05T11:34:36.539004Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"def profit_portfolio(A, portfolio):\n    f = np.array([profit(A, algo) for algo in portfolio])\n    return f.reshape(-1, 1)","metadata":{"id":"U9Gklctc8wbf","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.540904Z","iopub.execute_input":"2025-09-05T11:34:36.541169Z","iopub.status.idle":"2025-09-05T11:34:36.560458Z","shell.execute_reply.started":"2025-09-05T11:34:36.541147Z","shell.execute_reply":"2025-09-05T11:34:36.559346Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"import numpy as np\nimport math\n\ndef novelty_score(population, archive, k):\n    pop_size = len(population)\n    archive_size = len(archive)\n    N = population[0].shape[0]\n\n    U = np.zeros((archive_size, 12))\n    D = np.zeros((pop_size, 12))\n\n    lower_indices = np.tril_indices(N, k=-1)\n\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = archive[:,mask]\n    flat = masked_data.reshape(masked_data.shape[0], -1)\n    tens = torch.tensor(np.array(flat), dtype=torch.float32)\n    ae_model.eval()\n    with torch.no_grad():\n        U = ae_model.encoder(tens).cpu().numpy().astype(np.float32)\n\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = population[:,mask]\n    flat = masked_data.reshape(masked_data.shape[0], -1)\n    tens = torch.tensor(np.array(flat), dtype=torch.float32)\n    ae_model.eval()\n    with torch.no_grad():\n        D = ae_model.encoder(tens).cpu().numpy().astype(np.float32)\n\n    all_descriptors = np.concatenate((U, D), axis=0)\n    total_descriptors = all_descriptors.shape[0]\n\n    scores = np.zeros((pop_size, 1))\n    for t in range(pop_size):\n        distances = np.linalg.norm(all_descriptors - D[t, :], axis=1)\n        self_index = archive_size + t\n        distances[self_index] = np.inf\n        sorted_dist = np.sort(distances)\n        finite_dists = sorted_dist[np.isfinite(sorted_dist)]\n        k_eff = min(k, len(finite_dists))\n        scores[t] = np.mean(finite_dists[:k_eff])\n\n    return scores","metadata":{"id":"gj-2M5N2Mq0T","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.561598Z","iopub.execute_input":"2025-09-05T11:34:36.561890Z","iopub.status.idle":"2025-09-05T11:34:36.581228Z","shell.execute_reply.started":"2025-09-05T11:34:36.561866Z","shell.execute_reply":"2025-09-05T11:34:36.580099Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"def performance_score(population, portfolio, R=10):\n    amount_algorithms = len(portfolio)\n    pop_size = population.shape[0]\n\n    performance_scores = np.zeros((pop_size, amount_algorithms))\n\n    for i in range(pop_size):\n        cumulative_profit = np.zeros(amount_algorithms)\n\n        for r in range(R):\n            profit_vec = profit_portfolio(population[i], portfolio)\n            profit_vec = profit_vec.flatten()\n            cumulative_profit += profit_vec\n\n        performance_scores[i, :] = cumulative_profit / R\n\n    for i in range(pop_size):\n        target_value = performance_scores[i, 0]\n        other_values = performance_scores[i, 1:]\n        performance_scores[i, 0] = target_value - np.max(other_values)\n\n    return performance_scores","metadata":{"id":"Ah6ZeQLiNUXv","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.582276Z","iopub.execute_input":"2025-09-05T11:34:36.582517Z","iopub.status.idle":"2025-09-05T11:34:36.604580Z","shell.execute_reply.started":"2025-09-05T11:34:36.582499Z","shell.execute_reply":"2025-09-05T11:34:36.603561Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"def evaluate(population, archive, portfolio, k, phi, R=10):\n    pop_size = population.shape[0]\n\n    novelty = novelty_score(population, archive, k)\n    performance = performance_score(population, portfolio, R)\n\n    novelty = np.asarray(novelty).flatten()\n\n    target_performance = np.asarray(performance[:, 0]).flatten()\n\n    novelty_std = (novelty - np.mean(novelty)) / np.std(novelty)\n    target_performance_std = (target_performance - np.mean(target_performance)) / np.std(target_performance)\n\n    fitness = phi * target_performance_std + (1 - phi) * novelty_std\n\n    return fitness.reshape(-1, 1)","metadata":{"id":"GiB3D3G5RAYI","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.605668Z","iopub.execute_input":"2025-09-05T11:34:36.606010Z","iopub.status.idle":"2025-09-05T11:34:36.629009Z","shell.execute_reply.started":"2025-09-05T11:34:36.605984Z","shell.execute_reply":"2025-09-05T11:34:36.627733Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def cross(instance_1, instance_2, N):\n    mask = ~np.eye(N, dtype=bool)\n    flat_1 = instance_1[mask].flatten()\n    flat_2 = instance_2[mask].flatten()\n\n    dimension = N * N - N\n    crossover_mask = np.random.randint(0, 2, dimension)\n\n    offspring1 = np.where(crossover_mask, flat_1, flat_2)\n    offspring2 = np.where(crossover_mask, flat_2, flat_1)\n\n    return offspring1, offspring2","metadata":{"id":"fiHL8gtARXIT","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.630250Z","iopub.execute_input":"2025-09-05T11:34:36.630606Z","iopub.status.idle":"2025-09-05T11:34:36.650086Z","shell.execute_reply.started":"2025-09-05T11:34:36.630573Z","shell.execute_reply":"2025-09-05T11:34:36.649104Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def mutation(instance, mutation_rate=0.01):\n    instance = instance.copy()\n    mask = np.random.rand(len(instance)) < mutation_rate\n    instance[mask] = np.random.uniform(-1, 1, np.sum(mask))\n    return instance","metadata":{"id":"cVDADXRySk9G","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.651010Z","iopub.execute_input":"2025-09-05T11:34:36.651302Z","iopub.status.idle":"2025-09-05T11:34:36.670921Z","shell.execute_reply.started":"2025-09-05T11:34:36.651276Z","shell.execute_reply":"2025-09-05T11:34:36.670088Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"def array_to_matrix(array, N):\n    matrix = np.zeros((N, N))\n    idx = 0\n    for i in range(N):\n        for j in range(N):\n            if i != j:\n                matrix[i, j] = array[idx]\n                idx += 1\n    return matrix","metadata":{"id":"dONbVukdSolO","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.671811Z","iopub.execute_input":"2025-09-05T11:34:36.672065Z","iopub.status.idle":"2025-09-05T11:34:36.689032Z","shell.execute_reply.started":"2025-09-05T11:34:36.672046Z","shell.execute_reply":"2025-09-05T11:34:36.688161Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def offspring(population, archive, portfolio, k, phi, mutation_rate=0.01, R=10):\n    pop_size, N, _ = population.shape\n    flat_size = N * N - N\n    \n    fitness_values = evaluate(population, archive, portfolio, k, phi, R)\n    indexes = np.arange(pop_size)\n\n    parents = []\n    for _ in range(2 * pop_size):\n        a, b = random.choices(indexes, k=2)\n        winner = a if fitness_values[a] > fitness_values[b] else b  # Cambia a < si es minimización\n        parents.append(winner)\n    parents = np.array(parents).reshape(pop_size, 2)\n\n    offspring_flat = np.zeros((pop_size, flat_size))\n    for i in range(0, pop_size, 2):\n        p1 = population[parents[i, 0]]\n        p2 = population[parents[i, 1]]\n        o1, o2 = cross(p1, p2, N)\n        o1 = mutation(o1, mutation_rate)\n        o2 = mutation(o2, mutation_rate)\n        offspring_flat[i] = o1\n        offspring_flat[i + 1] = o2\n\n    offspring_matrix = np.array([array_to_matrix(vec, N) for vec in offspring_flat])\n    return offspring_matrix","metadata":{"id":"KYoNX6RATQvT","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.690067Z","iopub.execute_input":"2025-09-05T11:34:36.690422Z","iopub.status.idle":"2025-09-05T11:34:36.714016Z","shell.execute_reply.started":"2025-09-05T11:34:36.690397Z","shell.execute_reply":"2025-09-05T11:34:36.713001Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"def update_archive(population, archive, portfolio, k, phi, ta, R=10):\n    pop_size = len(population)\n    pop_novelty = novelty_score(population, archive, k)\n    pop_perf = performance_score(population, portfolio, R)\n\n    for i in range(pop_size):\n        if random.random() < 0.01:\n            archive = np.append(archive, [population[i]], axis=0)\n        elif pop_perf[i, 0] > 0 and pop_novelty[i] > ta:\n            archive = np.append(archive, [population[i]], axis=0)\n\n    return archive","metadata":{"id":"oR-R8VUSTuHt","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.714785Z","iopub.execute_input":"2025-09-05T11:34:36.715107Z","iopub.status.idle":"2025-09-05T11:34:36.734645Z","shell.execute_reply.started":"2025-09-05T11:34:36.715086Z","shell.execute_reply":"2025-09-05T11:34:36.733577Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def update_ss(population, solution_set, portfolio, phi, tss, R=10):\n    pop_size = len(population)\n    pop_perf = performance_score(population, portfolio, R)\n\n    for i in range(pop_size):\n        if pop_perf[i, 0] > 0:\n            novelty = novelty_score(np.array([population[i]]), solution_set, k=1)[0]\n            if novelty > tss:\n                solution_set = np.append(solution_set, [population[i]], axis=0)\n\n    return solution_set","metadata":{"id":"mBep6yExUAvU","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.735722Z","iopub.execute_input":"2025-09-05T11:34:36.736075Z","iopub.status.idle":"2025-09-05T11:34:36.757105Z","shell.execute_reply.started":"2025-09-05T11:34:36.736046Z","shell.execute_reply":"2025-09-05T11:34:36.756000Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"def novelty_search(D, N, k, phi, generations, portfolio, ta, tss, R=10, mutation_rate=0.01, initial_archive = [], population = []):\n    if len(population) == 0:\n        population = initialise(D, N)\n    else:\n        population = population\n\n    if len(initial_archive) == 0:\n        archive = np.array([random.choice(population)])\n    else:\n        archive = initial_archive\n\n    solution_set = archive\n    archive = update_archive(population, archive, portfolio, k, phi, ta, R)\n    solution_set = update_ss(population, solution_set, portfolio, phi, tss, R)\n\n    for i in range(generations):\n        offspring_pop = offspring(population, archive, portfolio, k, phi, mutation_rate, R)\n\n        # Evaluar población original y offspring\n        combined = np.concatenate((population, offspring_pop), axis=0)\n        fitness = evaluate(combined, archive, portfolio, k, phi, R).flatten()\n\n        # Dividir fitness en mitades\n        fitness_parents = fitness[:len(population)]\n        fitness_offspring = fitness[len(population):]\n\n        # Selección entre padre e hijo por posición\n        new_population = []\n        for j in range(len(population)):\n            if fitness_offspring[j] > fitness_parents[j]:\n                new_population.append(offspring_pop[j])\n            else:\n                new_population.append(population[j])\n                \n        population = np.array(new_population)\n\n        archive = update_archive(population, archive, portfolio, k, phi, ta, R)\n        solution_set = update_ss(population, solution_set, portfolio, phi, tss, R)\n        \n        if (i+1) in [250, 500, 750, 1000]:\n            name = portfolio[0].py_func.__name__\n            np.save(f\"{name}_{i+1}_gens_NS2_0_4.npy\", solution_set)\n            print(f\"[Checkpoint] Saved in generation {i+1}\")\n\n    return solution_set","metadata":{"id":"kIp3whqcUDZs","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.758113Z","iopub.execute_input":"2025-09-05T11:34:36.758386Z","iopub.status.idle":"2025-09-05T11:34:36.785053Z","shell.execute_reply.started":"2025-09-05T11:34:36.758364Z","shell.execute_reply":"2025-09-05T11:34:36.783934Z"}},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"Run the algorithm and save the results for 250, 500, 750 and 1000 generations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nset_global_seed(42)\n\nD = [50, 1]\nN = 20\nk = 3\nphi = 0.85\ngenerations = 1000\nta = 0.3\nts = 0.3\nR=3\n\ntraining_set, population_set = train_test_split(train,test_size=D[0] / len(train),random_state=42)\n\nprint(training_set.shape)\nprint(population_set.shape)\n\nportfolio_1 = np.array([insert_ls, two_opt_ls, swap_ls])\nportfolio_2 = np.array([swap_ls, two_opt_ls, insert_ls])\nportfolio_3 = np.array([two_opt_ls, swap_ls, insert_ls])\n\nsolution_set_1 = novelty_search(D, N, k, phi, generations, portfolio_1, ta, ts, R, 1 / ((N * N) - N), [], population_set)\nsolution_set_2 = novelty_search(D, N, k, phi, generations, portfolio_2, ta, ts, R, 1 / ((N * N) - N), [], population_set)\nsolution_set_3 = novelty_search(D, N, k, phi, generations, portfolio_3, ta, ts, R, 1 / ((N * N) - N), [], population_set)\n\nsize_1 = len(solution_set_1)\nsize_2 = len(solution_set_2)\nsize_3 = len(solution_set_3)\nprint(f\"Tamaños: {size_1}, {size_2}, {size_3}\")","metadata":{"id":"vHTrGOL7VJmF","outputId":"f7761279-67ab-4618-f83e-301ea816f4b5","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:34:36.788781Z","iopub.execute_input":"2025-09-05T11:34:36.789040Z","iopub.status.idle":"2025-09-05T11:35:38.033732Z","shell.execute_reply.started":"2025-09-05T11:34:36.789021Z","shell.execute_reply":"2025-09-05T11:35:38.032678Z"}},"outputs":[{"name":"stdout","text":"(3700, 20, 20)\n(50, 20, 20)\nTamaños: 190, 1, 1\n","output_type":"stream"}],"execution_count":69}]}