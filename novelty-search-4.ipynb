{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12406173,"sourceType":"datasetVersion","datasetId":7638246}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport random\nimport math\nfrom itertools import permutations\nfrom google.colab import files\nimport zipfile\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport shutil\nfrom google.colab import files\nimport glob\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"10FWNLT06Ask","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:31:50.117287Z","iopub.execute_input":"2025-08-19T20:31:50.117689Z","iopub.status.idle":"2025-08-19T20:31:58.415651Z","shell.execute_reply.started":"2025-08-19T20:31:50.117652Z","shell.execute_reply":"2025-08-19T20:31:58.414228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# @title\nimport os\nimport random\nimport numpy as np\nimport torch\n\ndef set_global_seed(seed=42):\n    # Python's built-in random module\n    random.seed(seed)\n\n    # NumPy\n    np.random.seed(seed)\n\n    # PyTorch (CPU y GPU)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # Para múltiples GPUs\n\n    # Determinismo en cuDNN (afecta rendimiento)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.use_deterministic_algorithms(True)\n    \n    # Para reproducibilidad total en transformaciones aleatorias\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # Para CUDA >=10.2\n\nset_global_seed(42)\n","metadata":{"id":"4wSaAcrZO7Cn","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:31:58.417082Z","iopub.execute_input":"2025-08-19T20:31:58.417649Z","iopub.status.idle":"2025-08-19T20:31:58.436101Z","shell.execute_reply.started":"2025-08-19T20:31:58.417610Z","shell.execute_reply":"2025-08-19T20:31:58.434690Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"AUTOENCODER","metadata":{"id":"aMR89cDu0T4s"}},{"cell_type":"code","source":"import numpy as np\n\nlolib = np.load('/kaggle/input/inastancias-mezclado/todo_normalizado_mezclado.npy')\nprint(lolib.shape)\naleatorio = np.load('/kaggle/input/inastancias-mezclado/instancias_aleatorias.npy')\nprint(aleatorio.shape)\ninstancias = np.load('/kaggle/input/inastancias-mezclado/instancias_mezclado.npy')\nprint(instancias.shape)\ntrain_3, test_3 = train_test_split(instancias, test_size=0.2, random_state=42)\ntrain = train_3\nvalidacion = test_3\ntest = test_3\nset_global_seed(42)\nprint(train.shape)","metadata":{"id":"Ln8GO3q_1inU","outputId":"96bb152a-ac2c-4ff5-b1fe-e7f72410e61a","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:31:58.439085Z","iopub.execute_input":"2025-08-19T20:31:58.440196Z","iopub.status.idle":"2025-08-19T20:31:58.892445Z","shell.execute_reply.started":"2025-08-19T20:31:58.440147Z","shell.execute_reply":"2025-08-19T20:31:58.891405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# @title\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass Autoencoder(nn.Module):\n    def __init__(self, input_dim, latent_dim, hidden_dim=80):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, latent_dim),\n            nn.Tanh()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        z = self.encoder(x)\n        out = self.decoder(z)\n        return out\n\ndef ae_loss(recon_x, x):\n    return F.mse_loss(recon_x, x, reduction='mean')\n\ndef train_autoencoder(model, data, epochs=50, batch_size=64, lr=1e-3):\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    for epoch in range(epochs):\n        model.train()\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i+batch_size]\n            optimizer.zero_grad()\n            recon = model(batch)\n            loss = ae_loss(recon, batch)\n            loss.backward()\n            optimizer.step()\n\ndef get_ae_latents(model, data, batch_size=64):\n    model.eval()\n    latents = []\n    with torch.no_grad():\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i+batch_size]\n            z = model.encoder(batch)\n            latents.append(z)\n    return torch.cat(latents, dim=0)\n\ndef train_autoencoder_from_matrices(matrix_data, N, latent_dim=12, hidden_dim=80, epochs=15, batch_size=32, lr=1e-3):\n    \"\"\"\n    matrix_data: list or np.ndarray of shape (num_instances, N, N)\n    N: size of each square matrix (e.g. 20)\n    \"\"\"\n    matrix_array = np.array(matrix_data, dtype=np.float32)\n\n    # Mask to remove diagonal\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = matrix_array[:, mask]\n\n    # Flatten each masked matrix into a vector\n    flat_data = masked_data.reshape(masked_data.shape[0], -1)\n\n    # Convert to torch tensor\n    tensor_data = torch.tensor(flat_data, dtype=torch.float32)\n\n    # Define and train the model\n    input_dim = tensor_data.shape[1]\n    ae_model = Autoencoder(input_dim=input_dim, latent_dim=latent_dim, hidden_dim=hidden_dim)\n    train_autoencoder(ae_model, tensor_data, epochs=epochs, batch_size=batch_size, lr=lr)\n\n    # Get latent representation\n    latents = get_ae_latents(ae_model, tensor_data, batch_size=batch_size)\n\n    return latents, ae_model","metadata":{"id":"hK3hcrCw1su_","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:31:58.893811Z","iopub.execute_input":"2025-08-19T20:31:58.894214Z","iopub.status.idle":"2025-08-19T20:31:58.910847Z","shell.execute_reply.started":"2025-08-19T20:31:58.894180Z","shell.execute_reply":"2025-08-19T20:31:58.909515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"set_global_seed(42)\nz, ae_model = train_autoencoder_from_matrices(train, 20)\nprint(np.max(z.numpy()))\nprint(np.mean(z.numpy()))","metadata":{"id":"IcogEkTXXxMt","outputId":"152b307c-88a2-4caa-a171-ea638fe250b2","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:31:58.911981Z","iopub.execute_input":"2025-08-19T20:31:58.912401Z","iopub.status.idle":"2025-08-19T20:32:09.713686Z","shell.execute_reply.started":"2025-08-19T20:31:58.912359Z","shell.execute_reply":"2025-08-19T20:32:09.711994Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ALGORITHMS","metadata":{"id":"zfRDMSxf30oA"}},{"cell_type":"markdown","source":"Profit permutation","metadata":{"id":"gAH3CX-L3TFg"}},{"cell_type":"code","source":"import numpy as np\nfrom numba import njit\n\n@njit\ndef profit_permutation(A, sigma):\n    \"\"\"\n    Compute the profit for a permutation sigma on matrix A,\n    summing only the upper triangular part (excluding diagonal).\n    \"\"\"\n    total = 0.0\n    N = len(sigma)\n    for i in range(N):\n        for j in range(i + 1, N):  # Upper triangle only\n            total += A[sigma[i], sigma[j]]\n    return total","metadata":{"id":"Dbzx2mjQ9OJz","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:09.714882Z","iopub.execute_input":"2025-08-19T20:32:09.715383Z","iopub.status.idle":"2025-08-19T20:32:11.831985Z","shell.execute_reply.started":"2025-08-19T20:32:09.715347Z","shell.execute_reply":"2025-08-19T20:32:11.830348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2-opt","metadata":{"id":"h6cBJdF63WMp"}},{"cell_type":"code","source":"@njit\ndef two_opt_ls(A, rand_indices):\n    N = A.shape[0]\n    sigma = np.arange(N)\n    for i in range(N-1, 0, -1):\n        j = rand_indices[N - 1 - i]\n        sigma[i], sigma[j] = sigma[j], sigma[i]\n\n    a = profit_permutation(A, sigma)\n    improvement = True\n\n    while improvement:\n        improvement = False\n        for i in range(N):\n            for j in range(i+1, N):\n                # Reverse segment in-place\n                sigma[i:j+1] = sigma[i:j+1][::-1]\n                b = profit_permutation(A, sigma)\n                if b > a:\n                    a = b\n                    improvement = True\n                    break  # restart\n                else:\n                    # Undo reversal\n                    sigma[i:j+1] = sigma[i:j+1][::-1]\n            if improvement:\n                break\n\n    return sigma","metadata":{"id":"QuPmI5nC9tat","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:11.833743Z","iopub.execute_input":"2025-08-19T20:32:11.834898Z","iopub.status.idle":"2025-08-19T20:32:11.846170Z","shell.execute_reply.started":"2025-08-19T20:32:11.834828Z","shell.execute_reply":"2025-08-19T20:32:11.844550Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Swap","metadata":{"id":"HTZSLMjj3cc5"}},{"cell_type":"code","source":"@njit\ndef swap_ls(A, rand_indices):\n    \"\"\"\n    Local search with pairwise swap moves to maximize profit.\n    Optimized with Numba and in-place swaps.\n    \"\"\"\n    N = A.shape[0]\n\n    # Generate initial random permutation (Fisher-Yates shuffle)\n    sigma = np.arange(N)\n    for i in range(N - 1, 0, -1):\n        j = rand_indices[N - 1 - i]\n        sigma[i], sigma[j] = sigma[j], sigma[i]\n\n    current_profit = profit_permutation(A, sigma)\n    improvement = True\n\n    while improvement:\n        improvement = False\n        for i in range(N):\n            for j in range(i + 1, N):\n                # Swap in-place\n                sigma[i], sigma[j] = sigma[j], sigma[i]\n                new_profit = profit_permutation(A, sigma)\n\n                if new_profit > current_profit:\n                    current_profit = new_profit\n                    improvement = True\n                    break  # Restart search after improvement\n                else:\n                    # Undo swap\n                    sigma[i], sigma[j] = sigma[j], sigma[i]\n            if improvement:\n                break\n\n    return sigma","metadata":{"id":"y0BV5n8h9vxw","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:11.847303Z","iopub.execute_input":"2025-08-19T20:32:11.847637Z","iopub.status.idle":"2025-08-19T20:32:11.910023Z","shell.execute_reply.started":"2025-08-19T20:32:11.847613Z","shell.execute_reply":"2025-08-19T20:32:11.908818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Insert","metadata":{"id":"Db3zNgmK3d96"}},{"cell_type":"code","source":"@njit\ndef insert_ls(A, rand_indices):\n    N = A.shape[0]\n    sigma = np.arange(N)\n    for i in range(N-1, 0, -1):\n        j = rand_indices[N - 1 - i]\n        sigma[i], sigma[j] = sigma[j], sigma[i]\n\n    a = profit_permutation(A, sigma)\n    improvement = True\n\n    while improvement:\n        improvement = False\n        for i in range(N):\n            for j in range(N):\n                if i == j:\n                    continue\n                sigma_copy = sigma.copy()\n                temp = sigma_copy[i]\n                if i < j:\n                    for k in range(i, j):\n                        sigma_copy[k] = sigma_copy[k+1]\n                else:\n                    for k in range(i, j, -1):\n                        sigma_copy[k] = sigma_copy[k-1]\n                sigma_copy[j] = temp\n\n                b = profit_permutation(A, sigma_copy)\n                if b > a:\n                    sigma = sigma_copy\n                    a = b\n                    improvement = True\n                    break\n            if improvement:\n                break\n\n    return sigma","metadata":{"id":"Td65031s92Sr","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:11.914457Z","iopub.execute_input":"2025-08-19T20:32:11.915081Z","iopub.status.idle":"2025-08-19T20:32:11.952376Z","shell.execute_reply.started":"2025-08-19T20:32:11.915044Z","shell.execute_reply":"2025-08-19T20:32:11.950406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Profit","metadata":{"id":"73f8-ETO3jmG"}},{"cell_type":"code","source":"# @title\ndef profit(A, algorithm):\n    rand_indices = [np.random.randint(0, i+1) for i in range(N-1, 0, -1)]\n    sigma = np.array(algorithm(A, rand_indices))\n    idx = sigma.astype(int)\n\n    A_sub = A[np.ix_(idx, idx)]\n    total_sum = np.sum(np.triu(A_sub, k=1))\n    return total_sum","metadata":{"id":"8RBq-DJZ8ZTg","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:11.953972Z","iopub.execute_input":"2025-08-19T20:32:11.954460Z","iopub.status.idle":"2025-08-19T20:32:11.991909Z","shell.execute_reply.started":"2025-08-19T20:32:11.954422Z","shell.execute_reply":"2025-08-19T20:32:11.990279Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"NOVELTY SEARCH","metadata":{"id":"u-SPcwXe0SET"}},{"cell_type":"markdown","source":"Initialise","metadata":{"id":"9Qtfcvn335Gj"}},{"cell_type":"code","source":"# @title\ndef initialise(D, N):\n    # D[0] = número de instancias, D[1] = valor máximo para la distribución uniforme (-D[1], D[1])\n    num_instancias = D[0]\n    max_valor = D[1]\n\n    population = np.empty((num_instancias, N, N))\n\n    for idx in range(num_instancias):\n        A = np.random.uniform(-max_valor, max_valor, size=(N, N))\n        np.fill_diagonal(A, 0)\n        population[idx] = A\n    return population\n","metadata":{"id":"5_N4PMGs5393","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:11.993915Z","iopub.execute_input":"2025-08-19T20:32:11.995296Z","iopub.status.idle":"2025-08-19T20:32:12.025699Z","shell.execute_reply.started":"2025-08-19T20:32:11.994750Z","shell.execute_reply":"2025-08-19T20:32:12.024393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Profit portfolio","metadata":{"id":"ts4FBAXl39Ic"}},{"cell_type":"code","source":"# @title\ndef profit_portfolio(A, portfolio):\n    f = np.array([profit(A, algo) for algo in portfolio])\n    return f.reshape(-1, 1)","metadata":{"id":"U9Gklctc8wbf","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.027479Z","iopub.execute_input":"2025-08-19T20:32:12.027883Z","iopub.status.idle":"2025-08-19T20:32:12.060185Z","shell.execute_reply.started":"2025-08-19T20:32:12.027848Z","shell.execute_reply":"2025-08-19T20:32:12.058558Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Novelty score","metadata":{"id":"odOlYLFf4Cuo"}},{"cell_type":"code","source":"# @title\nimport numpy as np\nimport math\n\ndef novelty_score(population, archive, k):\n    pop_size = len(population)\n    archive_size = len(archive)\n    N = population[0].shape[0]\n\n    U = np.zeros((archive_size, 12))\n    D = np.zeros((pop_size, 12))\n\n    lower_indices = np.tril_indices(N, k=-1)\n\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = archive[:,mask]\n    flat = masked_data.reshape(masked_data.shape[0], -1)\n    tens = torch.tensor(np.array(flat), dtype=torch.float32)\n    ae_model.eval()\n    with torch.no_grad():\n        U = ae_model.encoder(tens).cpu().numpy().astype(np.float32)\n\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = population[:,mask]\n    flat = masked_data.reshape(masked_data.shape[0], -1)\n    tens = torch.tensor(np.array(flat), dtype=torch.float32)\n    ae_model.eval()\n    with torch.no_grad():\n        D = ae_model.encoder(tens).cpu().numpy().astype(np.float32)\n\n    all_descriptors = np.concatenate((U, D), axis=0)\n    total_descriptors = all_descriptors.shape[0]\n\n    scores = np.zeros((pop_size, 1))\n    for t in range(pop_size):\n        distances = np.linalg.norm(all_descriptors - D[t, :], axis=1)\n        self_index = archive_size + t\n        distances[self_index] = np.inf\n        sorted_dist = np.sort(distances)\n        finite_dists = sorted_dist[np.isfinite(sorted_dist)]\n        k_eff = min(k, len(finite_dists))\n        scores[t] = np.mean(finite_dists[:k_eff])\n\n    return scores","metadata":{"id":"gj-2M5N2Mq0T","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.062050Z","iopub.execute_input":"2025-08-19T20:32:12.062469Z","iopub.status.idle":"2025-08-19T20:32:12.096310Z","shell.execute_reply.started":"2025-08-19T20:32:12.062440Z","shell.execute_reply":"2025-08-19T20:32:12.094384Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Performance score","metadata":{"id":"6LtG1rBm4E2u"}},{"cell_type":"code","source":"def performance_score(population, portfolio, R=10):\n    amount_algorithms = len(portfolio)\n    pop_size = population.shape[0]\n\n    performance_scores = np.zeros((pop_size, amount_algorithms))\n\n    for i in range(pop_size):\n        # Inicializar acumulador para R ejecuciones\n        cumulative_profit = np.zeros(amount_algorithms)\n\n        for r in range(R):\n            profit_vec = profit_portfolio(population[i], portfolio)\n            profit_vec = profit_vec.flatten()\n            cumulative_profit += profit_vec\n\n        # Promediar el resultado sobre R ejecuciones\n        performance_scores[i, :] = cumulative_profit / R\n\n    # Ajustar el score del solver en la posición 0\n    for i in range(pop_size):\n        target_value = performance_scores[i, 0]\n        other_values = performance_scores[i, 1:]\n        performance_scores[i, 0] = target_value - np.max(other_values)\n\n    return performance_scores","metadata":{"id":"Ah6ZeQLiNUXv","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.098465Z","iopub.execute_input":"2025-08-19T20:32:12.098777Z","iopub.status.idle":"2025-08-19T20:32:12.139463Z","shell.execute_reply.started":"2025-08-19T20:32:12.098757Z","shell.execute_reply":"2025-08-19T20:32:12.137702Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Fitness (novelty* phi + performance* (1-phi))","metadata":{"id":"wQW67oM64JnY"}},{"cell_type":"code","source":"def evaluate(population, archive, portfolio, k, phi, R=10):\n    pop_size = population.shape[0]\n\n    novelty = novelty_score(population, archive, k)\n    performance = performance_score(population, portfolio, R)\n\n    novelty = np.asarray(novelty).flatten()\n\n    target_performance = np.asarray(performance[:, 0]).flatten()\n\n    novelty_std = (novelty - np.mean(novelty)) / np.std(novelty)\n    target_performance_std = (target_performance - np.mean(target_performance)) / np.std(target_performance)\n\n    fitness = phi * target_performance_std + (1 - phi) * novelty_std\n\n    return fitness.reshape(-1, 1)","metadata":{"id":"GiB3D3G5RAYI","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.140957Z","iopub.execute_input":"2025-08-19T20:32:12.141681Z","iopub.status.idle":"2025-08-19T20:32:12.169202Z","shell.execute_reply.started":"2025-08-19T20:32:12.141618Z","shell.execute_reply":"2025-08-19T20:32:12.167670Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cross","metadata":{"id":"2yFkddwm4WK9"}},{"cell_type":"code","source":"# @title\ndef cross(instance_1, instance_2, N):\n    mask = ~np.eye(N, dtype=bool)\n    flat_1 = instance_1[mask].flatten()\n    flat_2 = instance_2[mask].flatten()\n\n    dimension = N * N - N\n    crossover_mask = np.random.randint(0, 2, dimension)\n\n    offspring1 = np.where(crossover_mask, flat_1, flat_2)\n    offspring2 = np.where(crossover_mask, flat_2, flat_1)\n\n    return offspring1, offspring2","metadata":{"id":"fiHL8gtARXIT","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.170419Z","iopub.execute_input":"2025-08-19T20:32:12.170713Z","iopub.status.idle":"2025-08-19T20:32:12.208920Z","shell.execute_reply.started":"2025-08-19T20:32:12.170692Z","shell.execute_reply":"2025-08-19T20:32:12.207641Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Mutation","metadata":{"id":"4fdRkZ904YE-"}},{"cell_type":"code","source":"# @title\ndef mutation(instance, mutation_rate=0.01):\n    instance = instance.copy()\n    mask = np.random.rand(len(instance)) < mutation_rate\n    instance[mask] = np.random.uniform(-1, 1, np.sum(mask))\n    return instance","metadata":{"id":"cVDADXRySk9G","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.209988Z","iopub.execute_input":"2025-08-19T20:32:12.210390Z","iopub.status.idle":"2025-08-19T20:32:12.242532Z","shell.execute_reply.started":"2025-08-19T20:32:12.210358Z","shell.execute_reply":"2025-08-19T20:32:12.240851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Array to matrix","metadata":{"id":"tyzHRc5G4ZVv"}},{"cell_type":"code","source":"# @title\ndef array_to_matrix(array, N):\n    matrix = np.zeros((N, N))\n    idx = 0\n    for i in range(N):\n        for j in range(N):\n            if i != j:\n                matrix[i, j] = array[idx]\n                idx += 1\n    return matrix","metadata":{"id":"dONbVukdSolO","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.244069Z","iopub.execute_input":"2025-08-19T20:32:12.244443Z","iopub.status.idle":"2025-08-19T20:32:12.286179Z","shell.execute_reply.started":"2025-08-19T20:32:12.244416Z","shell.execute_reply":"2025-08-19T20:32:12.285100Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Offsprings","metadata":{"id":"-fyotR0J4bOe"}},{"cell_type":"code","source":"# @title\nimport numpy as np\nimport random\n\n# @title\n# def offspring(population, archive, portfolio, k, phi, mutation_rate=0.01):\n#     pop_size, N, _ = population.shape\n#     flat_size = N * N - N\n\n#     fitness_values = evaluate(population, archive, portfolio, k, phi)\n#     indexes = np.arange(pop_size)\n\n#     indexes_for_cross = np.zeros(pop_size, dtype=int)\n#     for i in range(pop_size):\n#         a, b = random.choices(indexes, k=2)\n#         indexes_for_cross[i] = a if fitness_values[a] > fitness_values[b] else b\n\n#     parents = random.choices(indexes_for_cross.tolist(), k=2 * pop_size)\n#     parents = np.array(parents).reshape(pop_size, 2)\n\n#     offspring_flat = np.zeros((pop_size, flat_size))\n#     for i in range(0, pop_size, 2):\n#         p1 = population[parents[i, 0]]\n#         p2 = population[parents[i, 1]]\n#         o1, o2 = cross(p1, p2, N)\n#         o1 = mutation(o1)\n#         o2 = mutation(o2)\n#         offspring_flat[i] = o1\n#         offspring_flat[i + 1] = o2\n\n#     offspring_matrix = np.array([array_to_matrix(vec, N) for vec in offspring_flat])\n#     return offspring_matrix\n    \ndef offspring(population, archive, portfolio, k, phi, mutation_rate=0.01, R=10):\n    pop_size, N, _ = population.shape\n    flat_size = N * N - N\n\n    # Calcular fitness para cada individuo\n    fitness_values = evaluate(population, archive, portfolio, k, phi, R)\n    indexes = np.arange(pop_size)\n\n    # Seleccionar 2 * pop_size padres usando torneo binario\n    parents = []\n    for _ in range(2 * pop_size):\n        a, b = random.choices(indexes, k=2)\n        winner = a if fitness_values[a] > fitness_values[b] else b  # Cambia a < si es minimización\n        parents.append(winner)\n    parents = np.array(parents).reshape(pop_size, 2)\n\n    # Generar descendencia\n    offspring_flat = np.zeros((pop_size, flat_size))\n    for i in range(0, pop_size, 2):\n        p1 = population[parents[i, 0]]\n        p2 = population[parents[i, 1]]\n        o1, o2 = cross(p1, p2, N)\n        o1 = mutation(o1, mutation_rate)\n        o2 = mutation(o2, mutation_rate)\n        offspring_flat[i] = o1\n        offspring_flat[i + 1] = o2\n\n    # Convertir a matrices de adyacencia\n    offspring_matrix = np.array([array_to_matrix(vec, N) for vec in offspring_flat])\n    return offspring_matrix","metadata":{"id":"KYoNX6RATQvT","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.287334Z","iopub.execute_input":"2025-08-19T20:32:12.287637Z","iopub.status.idle":"2025-08-19T20:32:12.320793Z","shell.execute_reply.started":"2025-08-19T20:32:12.287614Z","shell.execute_reply":"2025-08-19T20:32:12.319540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Update archive","metadata":{"id":"QzarLSs24dwg"}},{"cell_type":"code","source":"# @title\ndef update_archive(population, archive, portfolio, k, phi, ta, R=10):\n    pop_size = len(population)\n    pop_novelty = novelty_score(population, archive, k)\n    pop_perf = performance_score(population, portfolio, R)\n\n    for i in range(pop_size):\n        # 1% de probabilidad de añadir la instancia\n        if random.random() < 0.01:\n            archive = np.append(archive, [population[i]], axis=0)\n        elif pop_perf[i, 0] > 0 and pop_novelty[i] > ta:\n            archive = np.append(archive, [population[i]], axis=0)\n\n    return archive","metadata":{"id":"oR-R8VUSTuHt","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.322771Z","iopub.execute_input":"2025-08-19T20:32:12.323185Z","iopub.status.idle":"2025-08-19T20:32:12.359277Z","shell.execute_reply.started":"2025-08-19T20:32:12.323157Z","shell.execute_reply":"2025-08-19T20:32:12.357683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Update solution set","metadata":{"id":"jogvefPw4fSd"}},{"cell_type":"code","source":"# @title\ndef update_ss(population, solution_set, portfolio, phi, tss, R=10):\n    pop_size = len(population)\n    pop_perf = performance_score(population, portfolio, R)\n\n    for i in range(pop_size):\n        if pop_perf[i, 0] > 0:\n            novelty = novelty_score(np.array([population[i]]), solution_set, k=1)[0]\n            if novelty > tss:\n                solution_set = np.append(solution_set, [population[i]], axis=0)\n\n    return solution_set","metadata":{"id":"mBep6yExUAvU","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.360756Z","iopub.execute_input":"2025-08-19T20:32:12.361099Z","iopub.status.idle":"2025-08-19T20:32:12.393598Z","shell.execute_reply.started":"2025-08-19T20:32:12.361074Z","shell.execute_reply":"2025-08-19T20:32:12.391108Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Novelty search","metadata":{"id":"G36RAH0R4hod"}},{"cell_type":"code","source":"# @title\ndef novelty_search(D, N, k, phi, generations, portfolio, ta, tss, R=10, mutation_rate=0.01, initial_archive = [], population = []):\n    if len(population) == 0:\n        population = initialise(D, N)\n    else:\n        population = population\n\n    if len(initial_archive) == 0:\n        archive = np.array([random.choice(population)])\n    else:\n        archive = initial_archive\n\n    solution_set = archive\n    archive = update_archive(population, archive, portfolio, k, phi, ta, R)\n    solution_set = update_ss(population, solution_set, portfolio, phi, tss, R)\n\n    for i in range(generations):\n        offspring_pop = offspring(population, archive, portfolio, k, phi, mutation_rate, R)\n\n        # Evaluar población original y offspring\n        combined = np.concatenate((population, offspring_pop), axis=0)\n        fitness = evaluate(combined, archive, portfolio, k, phi, R).flatten()\n\n        # Dividir fitness en mitades\n        fitness_parents = fitness[:len(population)]\n        fitness_offspring = fitness[len(population):]\n\n        # Selección entre padre e hijo por posición\n        new_population = []\n        for j in range(len(population)):\n            if fitness_offspring[j] > fitness_parents[j]:\n                new_population.append(offspring_pop[j])\n            else:\n                new_population.append(population[j])\n                \n        population = np.array(new_population)\n\n        archive = update_archive(population, archive, portfolio, k, phi, ta, R)\n        solution_set = update_ss(population, solution_set, portfolio, phi, tss, R)\n\n\n        # print(i)\n        \n        if (i+1) in [250, 500, 750, 1000]:\n            name = portfolio[0].py_func.__name__\n            np.save(f\"{name}_{i+1}_gens_NS2_0_4.npy\", solution_set)\n            print(f\"[Checkpoint] Guardado en generación {i+1}\")\n\n    return solution_set","metadata":{"id":"kIp3whqcUDZs","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.395320Z","iopub.execute_input":"2025-08-19T20:32:12.395767Z","iopub.status.idle":"2025-08-19T20:32:12.430574Z","shell.execute_reply.started":"2025-08-19T20:32:12.395738Z","shell.execute_reply":"2025-08-19T20:32:12.429196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"SAVE THE FILES AND PLOT THE RESULTS","metadata":{"id":"cJK-eJp64mrb"}},{"cell_type":"markdown","source":"Save files","metadata":{"id":"cSeMVtfM4uK4"}},{"cell_type":"markdown","source":"Plot PCA","metadata":{"id":"D9ZAHVW44xp_"}},{"cell_type":"code","source":"# @title\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_pca_groups(*data_matrices, labels=None):\n    # Calcular los tamaños de cada grupo\n    sizes = [len(dm) for dm in data_matrices]\n    cumulative_sizes = np.cumsum([0] + sizes)\n\n    # Combinar todas las matrices en una\n    matrix = np.vstack(data_matrices)\n    matrix = matrix.reshape(matrix.shape[0], -1)  # Asegura que es 2D\n\n    # Estandarizar\n    scaler = StandardScaler()\n    matrix = scaler.fit_transform(matrix)\n\n    # Aplicar PCA\n    pca = PCA(n_components=2)\n    reduced_data = pca.fit_transform(matrix)\n\n    # Imprimir varianza explicada\n    print(\"Varianza explicada acumulada:\", np.cumsum(pca.explained_variance_ratio_))\n\n    # Colores y marcadores predeterminados\n    default_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n    default_markers = ['o', '*', 's', 'P', '^', 'x']\n\n    # Graficar cada grupo\n    plt.figure(figsize=(8, 5))\n    for i in range(len(data_matrices)):\n        group = reduced_data[cumulative_sizes[i]:cumulative_sizes[i+1], :]\n        label = labels[i] if labels and i < len(labels) else f\"Grupo {i+1}\"\n        color = default_colors[i % len(default_colors)]\n        marker = default_markers[i % len(default_markers)]\n        plt.scatter(group[:, 0], group[:, 1], s=1, marker=marker, label=label, color=color)\n\n    plt.xlabel('x0', fontsize=12)\n    plt.ylabel('x1', fontsize=12)\n    plt.title(r'$\\mathit{NS_{ls}}$ instances over feature space', fontsize=14)\n    plt.legend(title=\"target\", loc='best', frameon=True)\n    plt.grid(False)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"id":"bSoHuvryfAgp","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.431969Z","iopub.execute_input":"2025-08-19T20:32:12.432333Z","iopub.status.idle":"2025-08-19T20:32:12.746705Z","shell.execute_reply.started":"2025-08-19T20:32:12.432303Z","shell.execute_reply":"2025-08-19T20:32:12.745375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compute descriptors","metadata":{"id":"6tDdudMP41cI"}},{"cell_type":"code","source":"# @title\ndef compute_descriptors(solution_set):\n\n    N = solution_set.shape[1]\n    mask = ~np.eye(N, dtype=bool)\n    masked_data = solution_set[:,mask]\n    flat = masked_data.reshape(masked_data.shape[0], -1)\n    tens = torch.tensor(np.array(flat), dtype=torch.float32)\n    ae_model.eval()\n    with torch.no_grad():\n        data_matrix = ae_model.encoder(tens).cpu().numpy().astype(np.float32)\n    return data_matrix\n","metadata":{"id":"AjF-osQkVVNo","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.748524Z","iopub.execute_input":"2025-08-19T20:32:12.749299Z","iopub.status.idle":"2025-08-19T20:32:12.760332Z","shell.execute_reply.started":"2025-08-19T20:32:12.749218Z","shell.execute_reply":"2025-08-19T20:32:12.758388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import time\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nset_global_seed(42)\n\nD = [50, 1]\nN = 20\nk = 3\nphi = 0\ngenerations = 1000\nta = 0.3\nts = 0.3\nR=3\n\nentrenamiento, populacion = train_test_split(train,test_size=D[0] / len(train),random_state=42)\n\nprint(entrenamiento.shape)\nprint(populacion.shape)\n\nportfolio_1 = np.array([insert_ls, two_opt_ls, swap_ls])\nportfolio_2 = np.array([swap_ls, two_opt_ls, insert_ls])\nportfolio_3 = np.array([two_opt_ls, swap_ls, insert_ls])\n\nsolution_set_1 = novelty_search(D, N, k, phi, generations, portfolio_1, ta, ts, R, 1 / ((N * N) - N), [], populacion)\nsolution_set_2 = novelty_search(D, N, k, phi, generations, portfolio_2, ta, ts, R, 1 / ((N * N) - N), [], populacion)\nsolution_set_3 = novelty_search(D, N, k, phi, generations, portfolio_3, ta, ts, R, 1 / ((N * N) - N), [], populacion)\n\nsize_1 = len(solution_set_1)\nsize_2 = len(solution_set_2)\nsize_3 = len(solution_set_3)\nprint(f\"Tamaños: {size_1}, {size_2}, {size_3}\")","metadata":{"id":"vHTrGOL7VJmF","outputId":"f7761279-67ab-4618-f83e-301ea816f4b5","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T20:32:12.761513Z","iopub.execute_input":"2025-08-19T20:32:12.761949Z","iopub.status.idle":"2025-08-19T23:06:10.772469Z","shell.execute_reply.started":"2025-08-19T20:32:12.761913Z","shell.execute_reply":"2025-08-19T23:06:10.766899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n# from sklearn.model_selection import train_test_split\n\n# # Asegurar comportamiento determinista\n# set_global_seed(42)\n# torch.use_deterministic_algorithms(True)\n# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n# os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n# torch.set_num_threads(1)\n\n# # Parámetros fijos\n# N = 20\n# k = 3\n# phi = 0.85\n# generations = 40\n# ta = 0.01\n# ts = 0.03\n# mutation_rate = 1 / ((N * N) - N)\n# portfolios = [\n#     np.array([insert_ls, two_opt_ls, swap_ls]),\n#     np.array([swap_ls, two_opt_ls, insert_ls]),\n#     np.array([two_opt_ls, swap_ls, insert_ls]),\n# ]\n\n# # Valores de D[0]\n# D_values = list(range(2, 105, 6))\n# mean_sizes_1 = []\n# mean_sizes_2 = []\n# mean_sizes_3 = []\n\n# repetitions = 3\n\n# for D0 in D_values:\n#     print(f\"\\nEjecutando para D[0]={D0}\")\n#     D = [D0, 1]\n\n#     sizes_1, sizes_2, sizes_3 = [], [], []\n\n#     for r in range(repetitions):\n#         set_global_seed(42 + r)  # Diferente semilla en cada repetición\n\n#         entrenamiento, populacion = train_test_split(train, test_size=D[0] / len(train), random_state=42 + r)\n\n#         # Asegurarse que la población sea par\n#         if len(populacion) % 2 != 0:\n#             populacion = populacion[:-1]\n\n#         s1 = novelty_search(D, N, k, phi, generations, portfolios[0], ta, ts, mutation_rate, entrenamiento, populacion)\n#         s2 = novelty_search(D, N, k, phi, generations, portfolios[1], ta, ts, mutation_rate, entrenamiento, populacion)\n#         s3 = novelty_search(D, N, k, phi, generations, portfolios[2], ta, ts, mutation_rate, entrenamiento, populacion)\n\n#         sizes_1.append(len(s1) - len(entrenamiento))\n#         sizes_2.append(len(s2) - len(entrenamiento))\n#         sizes_3.append(len(s3) - len(entrenamiento))\n\n#     mean_sizes_1.append(np.mean(sizes_1))\n#     mean_sizes_2.append(np.mean(sizes_2))\n#     mean_sizes_3.append(np.mean(sizes_3))\n\n# # Graficar los resultados\n# plt.figure(figsize=(10, 6))\n# plt.plot(D_values, mean_sizes_1, marker='o', label='Portfolio 1')\n# plt.plot(D_values, mean_sizes_2, marker='s', label='Portfolio 2')\n# plt.plot(D_values, mean_sizes_3, marker='^', label='Portfolio 3')\n# plt.xlabel(\"Cantidad de Instancias Iniciales (D[0])\")\n# plt.ylabel(\"Promedio de Nuevas Instancias Generadas\")\n# plt.title(\"Promedio de instancias generadas vs. número de instancias iniciales\")\n# plt.legend()\n# plt.grid(True)\n# plt.tight_layout()\n# plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.773416Z","iopub.status.idle":"2025-08-19T23:06:10.773893Z","shell.execute_reply.started":"2025-08-19T23:06:10.773716Z","shell.execute_reply":"2025-08-19T23:06:10.773733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n# import time\n# from sklearn.model_selection import train_test_split\n\n# # Asegurar comportamiento determinista\n# set_global_seed(42)\n# torch.use_deterministic_algorithms(True)\n# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n# os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n# torch.set_num_threads(1)\n\n# # Parámetros fijos\n# N = 20\n# k = 3\n# phi = 0.85\n# generations = 40\n# ta = 0.01\n# ts = 0.03\n# mutation_rate = 1 / ((N * N) - N)\n# portfolios = [\n#     np.array([insert_ls, two_opt_ls, swap_ls]),\n#     np.array([swap_ls, two_opt_ls, insert_ls]),\n#     np.array([two_opt_ls, swap_ls, insert_ls]),\n# ]\n\n# # Valores de D[0]\n# D_values = list(range(2, 105, 6))\n# mean_times_1 = []\n# mean_times_2 = []\n# mean_times_3 = []\n\n# repetitions = 3\n\n# for D0 in D_values:\n#     print(f\"\\nMidiendo tiempos para D[0]={D0}\")\n#     D = [D0, 1]\n\n#     times_1, times_2, times_3 = [], [], []\n\n#     for r in range(repetitions):\n#         set_global_seed(42 + r)\n#         entrenamiento, populacion = train_test_split(train, test_size=D[0] / len(train), random_state=42 + r)\n\n#         # Asegurar población par\n#         if len(populacion) % 2 != 0:\n#             populacion = populacion[:-1]\n\n#         # Portfolio 1\n#         start = time.time()\n#         _ = novelty_search(D, N, k, phi, generations, portfolios[0], ta, ts, mutation_rate, entrenamiento, populacion)\n#         times_1.append(time.time() - start)\n\n#         # Portfolio 2\n#         start = time.time()\n#         _ = novelty_search(D, N, k, phi, generations, portfolios[1], ta, ts, mutation_rate, entrenamiento, populacion)\n#         times_2.append(time.time() - start)\n\n#         # Portfolio 3\n#         start = time.time()\n#         _ = novelty_search(D, N, k, phi, generations, portfolios[2], ta, ts, mutation_rate, entrenamiento, populacion)\n#         times_3.append(time.time() - start)\n\n#     mean_times_1.append(np.mean(times_1))\n#     mean_times_2.append(np.mean(times_2))\n#     mean_times_3.append(np.mean(times_3))\n\n# # Graficar los resultados\n# plt.figure(figsize=(10, 6))\n# plt.plot(D_values, mean_times_1, marker='o', label='Portfolio 1')\n# plt.plot(D_values, mean_times_2, marker='s', label='Portfolio 2')\n# plt.plot(D_values, mean_times_3, marker='^', label='Portfolio 3')\n# plt.xlabel(\"Cantidad de Instancias Iniciales (D[0])\")\n# plt.ylabel(\"Tiempo promedio de ejecución (segundos)\")\n# plt.title(\"Tiempo de ejecución vs. número de instancias iniciales\")\n# plt.legend()\n# plt.grid(True)\n# plt.tight_layout()\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.775229Z","iopub.status.idle":"2025-08-19T23:06:10.775703Z","shell.execute_reply.started":"2025-08-19T23:06:10.775532Z","shell.execute_reply":"2025-08-19T23:06:10.775550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_matrix_0 = compute_descriptors(instancias)\ndata_aleatorio = compute_descriptors(aleatorio)\ndata_matrix_1 = compute_descriptors(solution_set_1)\ndata_matrix_2 = compute_descriptors(solution_set_2)\ndata_matrix_3 = compute_descriptors(solution_set_3)","metadata":{"id":"dtmej5751pLH","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.777777Z","iopub.status.idle":"2025-08-19T23:06:10.778177Z","shell.execute_reply.started":"2025-08-19T23:06:10.778004Z","shell.execute_reply":"2025-08-19T23:06:10.778020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 55# # Guardar archivos .npy con nombres adecuados\n# np.save(\"900_two_opt_0_85\", solution_set_3)\n# np.save(\"900_swap_0_85\", solution_set_2)\n# np.save(\"900_insert_0_85\", solution_set_1)\n\n# # np.save(get_filename_descriptors(D, N, k, phi, generations, portfolio_1[0], ta, ts), data_matrix_1)\n# # np.save(get_filename_descriptors(D, N, k, phi, generations, portfolio_2[0], ta, ts), data_matrix_2)\n# # np.save(get_filename_descriptors(D, N, k, phi, generations, portfolio_3[0], ta, ts), data_matrix_3)","metadata":{"id":"aZqfma1sDp47","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.780333Z","iopub.status.idle":"2025-08-19T23:06:10.780834Z","shell.execute_reply.started":"2025-08-19T23:06:10.780571Z","shell.execute_reply":"2025-08-19T23:06:10.780588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pca_groups(data_matrix_0, data_matrix_1, data_matrix_2, data_matrix_3, compute_descriptors(populacion))\nplot_pca_groups(data_matrix_1, data_matrix_2)","metadata":{"id":"mXmMxSba1uTj","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.783925Z","iopub.status.idle":"2025-08-19T23:06:10.784433Z","shell.execute_reply.started":"2025-08-19T23:06:10.784204Z","shell.execute_reply":"2025-08-19T23:06:10.784226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pca_groups(compute_descriptors(entrenamiento))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:07:09.358299Z","iopub.execute_input":"2025-08-19T23:07:09.358770Z","iopub.status.idle":"2025-08-19T23:07:09.800938Z","shell.execute_reply.started":"2025-08-19T23:07:09.358738Z","shell.execute_reply":"2025-08-19T23:07:09.799326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Revisar por que a veces el novelty score es 0.","metadata":{"id":"sGQ8Hf_Q3uHi","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.786298Z","iopub.status.idle":"2025-08-19T23:06:10.786689Z","shell.execute_reply.started":"2025-08-19T23:06:10.786539Z","shell.execute_reply":"2025-08-19T23:06:10.786554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# valor_insert = 0\n# valor_swap = 0\n# valor_two_opt = 0\n# vector_clasificacion = np.zeros((len(validacion),1))\n# for j in range(len(validacion)):\n#   instance = validacion[j]\n#   for i in range(10):\n#     valor_insert = valor_insert + profit(instance, insert)\n#     valor_swap = valor_swap + profit(instance, swap)\n#     valor_two_opt = valor_two_opt + profit(instance, two_opt)\n#   valor_insert = valor_insert / 10\n#   valor_swap = valor_swap / 10\n#   valor_two_opt = valor_two_opt / 10\n#   if valor_insert > valor_swap and valor_insert > valor_two_opt:\n#     vector_clasificacion[j] = 1\n#   elif valor_swap > valor_insert and valor_swap > valor_two_opt:\n#     vector_clasificacion[j] = 2\n#   elif valor_two_opt > valor_insert and valor_two_opt > valor_swap:\n#     vector_clasificacion[j] = 0\n#   valor_insert = 0\n#   valor_swap = 0\n#   valor_two_opt = 0\n","metadata":{"id":"lMdlrI2CGfov","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.788750Z","iopub.status.idle":"2025-08-19T23:06:10.789271Z","shell.execute_reply.started":"2025-08-19T23:06:10.788973Z","shell.execute_reply":"2025-08-19T23:06:10.788993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# from scipy.spatial.distance import cdist\n\n# def clasificacion(populacion_desc, validacion):\n#     # Paso 1: Calcular descriptores\n#     descriptores_validacion = compute_descriptors(validacion)\n\n#     # Paso 2: Calcular distancias (filas = validacion, columnas = poblacion)\n#     distancias = cdist(descriptores_validacion, populacion_desc, metric='euclidean')\n\n#     # Paso 3: Obtener índice del descriptor más cercano de la población\n#     indices_minimos = np.argmin(distancias, axis=1)  # uno por cada fila de validación\n\n#     return indices_minimos","metadata":{"id":"ZS9oX15VaY_K","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.792078Z","iopub.status.idle":"2025-08-19T23:06:10.792548Z","shell.execute_reply.started":"2025-08-19T23:06:10.792359Z","shell.execute_reply":"2025-08-19T23:06:10.792376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prediccion = clasificacion(poblacion_desc, validacion)\n# descriptores_validacion = compute_descriptors(validacion)\n# print(len(prediccion))","metadata":{"id":"fpA8ZYJcbNCH","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.794552Z","iopub.status.idle":"2025-08-19T23:06:10.794979Z","shell.execute_reply.started":"2025-08-19T23:06:10.794812Z","shell.execute_reply":"2025-08-19T23:06:10.794828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prediccion_2 = np.zeros((len(prediccion),1))\n# for i in range(len(prediccion)):\n#   if prediccion[i] <= len_two_opt:\n#     prediccion_2[i] = 0\n#   elif prediccion[i] <= len_two_opt + len_insert and prediccion[i] > len_two_opt:\n#     prediccion_2[i] = 1\n#   else:\n#     prediccion_2[i] = 2\n\n# import numpy as np\n\n# # Comparar elemento a elemento y contar coincidencias\n# coinciden = np.sum(vector_clasificacion == prediccion_2)\n# print(\"Coincidencias:\", coinciden)\n","metadata":{"id":"T8l2cdWxdusK","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.797078Z","iopub.status.idle":"2025-08-19T23:06:10.797584Z","shell.execute_reply.started":"2025-08-19T23:06:10.797355Z","shell.execute_reply":"2025-08-19T23:06:10.797376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# from scipy.spatial.distance import cdist\n\n# def evaluar_clasificacion(validacion):\n#     # Paso 1: Clasificación real según heurísticas (con profit promedio)\n#     vector_clasificacion = np.zeros((len(validacion), 1))\n\n#     for j in range(len(validacion)):\n#         instance = validacion[j]\n#         valor_insert = np.mean([profit(instance, insert) for _ in range(10)])\n#         valor_swap = np.mean([profit(instance, swap) for _ in range(10)])\n#         valor_two_opt = np.mean([profit(instance, two_opt) for _ in range(10)])\n\n#         if valor_insert > valor_swap and valor_insert > valor_two_opt:\n#             vector_clasificacion[j] = 1\n#         elif valor_swap > valor_insert and valor_swap > valor_two_opt:\n#             vector_clasificacion[j] = 2\n#         else:\n#             vector_clasificacion[j] = 0\n\n#     distancias = cdist(descriptores_validacion, poblacion_desc, metric='euclidean')\n#     indices_minimos = np.argmin(distancias, axis=1)\n\n#     prediccion_2 = np.zeros((len(indices_minimos), 1))\n#     for i in range(len(indices_minimos)):\n#         if indices_minimos[i] < len_two_opt:\n#             prediccion_2[i] = 0\n#         elif indices_minimos[i] < len_two_opt + len_insert and indices_minimos[i] >= len_two_opt:\n#             prediccion_2[i] = 1\n#         else:\n#             prediccion_2[i] = 2\n\n#     # Paso 3: Comparar clasificaciones\n#     coincidencias = np.sum(vector_clasificacion == prediccion_2)\n\n#     print(\"Coincidencias:\", coincidencias)\n#     return coincidencias, vector_clasificacion, prediccion_2\n","metadata":{"id":"zxkgI-oIuonT","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.800684Z","iopub.status.idle":"2025-08-19T23:06:10.801225Z","shell.execute_reply.started":"2025-08-19T23:06:10.800980Z","shell.execute_reply":"2025-08-19T23:06:10.801002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# coincidencias, _, _ = evaluar_clasificacion(validacion)\n# print(coincidencias)","metadata":{"id":"IuEuE6KbvRQG","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.802584Z","iopub.status.idle":"2025-08-19T23:06:10.803054Z","shell.execute_reply.started":"2025-08-19T23:06:10.802834Z","shell.execute_reply":"2025-08-19T23:06:10.802854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# from sklearn.neighbors import KNeighborsClassifier\n\n# def evaluar_clasificacion_knn(validacion, vector_clasificacion, k=3):\n#     # Crear etiquetas de clase para la población\n#     etiquetas_poblacion = np.concatenate((\n#         np.zeros(len_two_opt),              # Clase 0: two_opt\n#         np.ones(len_insert),                # Clase 1: insert\n#         np.full(len_swap, 2)                # Clase 2: swap\n#     ))\n\n#     # Entrenar clasificador k-NN\n#     clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n#     clf.fit(poblacion_desc, etiquetas_poblacion)\n\n#     # Predecir clases para las instancias de validación\n#     predicciones = clf.predict(descriptores_validacion).reshape(-1, 1)\n\n#     # Calcular coincidencias\n#     coincidencias = np.sum(vector_clasificacion == predicciones)\n#     print(f\"Coincidencias con k={k}:\", coincidencias)\n\n#     return coincidencias, vector_clasificacion, predicciones\n","metadata":{"id":"hDp1KDPXybjF","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.805776Z","iopub.status.idle":"2025-08-19T23:06:10.806425Z","shell.execute_reply.started":"2025-08-19T23:06:10.806209Z","shell.execute_reply":"2025-08-19T23:06:10.806231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# coincidencias_2, _, _ = evaluar_clasificacion_knn(validacion, vector_clasificacion, k=10000)","metadata":{"id":"sLcR8PT5yctR","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.809286Z","iopub.status.idle":"2025-08-19T23:06:10.809890Z","shell.execute_reply.started":"2025-08-19T23:06:10.809524Z","shell.execute_reply":"2025-08-19T23:06:10.809539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from google.colab import files\n# files.download('AE_30_1_20_3_0.85_300_two_opt_0.01_0.03_descriptor.npy')  # por ejemplo: 'resultados.csv'","metadata":{"id":"nllo5O0HXptL","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.811637Z","iopub.status.idle":"2025-08-19T23:06:10.812207Z","shell.execute_reply.started":"2025-08-19T23:06:10.812007Z","shell.execute_reply":"2025-08-19T23:06:10.812030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set_global_seed(42)\n# set_global_seed_2(42)\n\n# plot_autoencoder_latents(data_matrix_1, data_matrix_2, data_matrix_3)\n# # plot_autoencoder_latents(solution_set_1, solution_set_2, solution_set_3)","metadata":{"id":"yaixD6MZ5NTP","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.813972Z","iopub.status.idle":"2025-08-19T23:06:10.814356Z","shell.execute_reply.started":"2025-08-19T23:06:10.814170Z","shell.execute_reply":"2025-08-19T23:06:10.814182Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"GRAFCAR INSTANCIAS CONSEGUIDAS CON EL NS CON LOS DESCRIPTORES","metadata":{"id":"2j2LP07tyE-X"}},{"cell_type":"code","source":"# from google.colab import files\n# uploaded = files.upload()","metadata":{"id":"1Pp40mNnyEQE","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.816579Z","iopub.status.idle":"2025-08-19T23:06:10.817550Z","shell.execute_reply.started":"2025-08-19T23:06:10.817290Z","shell.execute_reply":"2025-08-19T23:06:10.817316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pickle\n\n# # Replace 'novelty_search_LOP_4_alg.pkl' with the actual file name\n# with open('NS_AE_20x20_seed_42.pkl', 'rb') as f:\n#     data_1 = pickle.load(f)\n\n# with open('novelty_search_LOP_4_alg.pkl', 'rb') as g:\n#     data_2 = pickle.load(g)\n\n# # Now you can use the 'data' object\n# print(type(data_2))\n","metadata":{"id":"hjpm2WWs3_js","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.818334Z","iopub.status.idle":"2025-08-19T23:06:10.818742Z","shell.execute_reply.started":"2025-08-19T23:06:10.818545Z","shell.execute_reply":"2025-08-19T23:06:10.818564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n\n# # Guardar el diccionario como archivo .npy\n# np.save('archivo_guardado_1.npy', data_1)\n# np.save('archivo_guardado_2.npy', data_2)\n# data_3 = np.load('instancias_aleatorias.npy')\n\n# print(data_3.shape)","metadata":{"id":"eKz-zfc34NfB","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.820498Z","iopub.status.idle":"2025-08-19T23:06:10.821885Z","shell.execute_reply.started":"2025-08-19T23:06:10.821401Z","shell.execute_reply":"2025-08-19T23:06:10.821446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# instancias_descriptores_1 = np.load('archivo_guardado_1.npy', allow_pickle=True)\n# combined_array_1 = np.concatenate(\n#     [data_1['2-opt'], data_1['swap'], data_1['insert']],\n#     axis=0\n# )\n# instancias_descriptores_2 = np.load('archivo_guardado_2.npy', allow_pickle=True)\n# combined_array_2 = np.concatenate(\n#     [data_2['2-opt'], data_2['swap'], data_2['insert']],\n#     axis=0\n# )\n# data_11 = data_1['2-opt']\n# data_12 = data_1['swap']\n# data_13 = data_1['insert']\n# data_21 = data_2['2-opt']\n# data_22 = data_2['swap']\n# data_23 = data_2['insert']\n# size_11 = len(data_11)\n# size_12 = len(data_12)\n# size_13 = len(data_13)\n# size_21 = len(data_21)\n# size_22 = len(data_22)\n# size_23 = len(data_23)\n# print(data_11.shape)\n# print(data_12.shape)\n# print(data_13.shape)\n# print(data_21.shape)\n# print(data_22.shape)\n# print(data_23.shape)\n# print(combined_array_1.shape)\n# print(combined_array_2.shape)\n# set_global_seed(42)\n# set_global_seed_2(42)\n# data_matrix_11 = compute_descriptors(data_11)\n# data_matrix_12 = compute_descriptors(data_12)\n# data_matrix_13 = compute_descriptors(data_13)\n# data_matrix_21 = compute_descriptors(data_21)\n# data_matrix_22 = compute_descriptors(data_22)\n# data_matrix_23 = compute_descriptors(data_23)\n# data_matrix_3 = compute_descriptors(data_3)\n\n","metadata":{"id":"oBW8Xkef4V45","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.823394Z","iopub.status.idle":"2025-08-19T23:06:10.823998Z","shell.execute_reply.started":"2025-08-19T23:06:10.823789Z","shell.execute_reply":"2025-08-19T23:06:10.823810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.decomposition import PCA\n# from sklearn.preprocessing import StandardScaler\n# import matplotlib.pyplot as plt\n# import numpy as np\n\n# matrix_11 = data_matrix_11\n# matrix_12 = data_matrix_12\n# matrix_13 = data_matrix_13\n# matrix_21 = data_matrix_21\n# matrix_22 = data_matrix_22\n# matrix_23 = data_matrix_23\n\n# matrix = np.vstack((matrix_11, matrix_12, matrix_13, matrix_21, matrix_22, matrix_23, data_matrix_3))\n\n# set_global_seed(42)\n# set_global_seed_2(42)\n\n# scaler = StandardScaler()\n# matrix = scaler.fit_transform(matrix)\n\n# pca = PCA()\n# reduced_data = pca.fit_transform(matrix)\n\n# group_11 = reduced_data[0:size_11, :]\n# group_12 = reduced_data[size_11:size_11+size_12, :]\n# group_13 = reduced_data[size_11+size_12:size_11+size_12+size_13, :]\n# group_21 = reduced_data[size_11+size_12+size_13:size_11+size_12+size_13+size_21, :]\n# group_22 = reduced_data[size_11+size_12+size_13+size_21:size_11+size_12+size_13+size_21+size_22, :]\n# group_23 = reduced_data[size_11+size_12+size_13+size_21+size_22:size_11+size_12+size_13+size_21+size_22+size_23, :]\n# group_3 = reduced_data[size_11+size_12+size_13+size_21+size_22+size_23:,:]\n\n# print(\"Varianza explicada acumulada:\", np.cumsum(pca.explained_variance_ratio_))\n\n# plt.figure(figsize=(8, 5))\n\n# # plt.scatter(group_11[:, 0], group_11[:, 1], s=20, marker='o', label=\"two_opt_AE\", color='#1f77b4')   # Azul\n# # plt.scatter(group_12[:, 0], group_12[:, 1], s=20, marker='o', label=\"swap_AE\", color='#ff7f0e')       # Naranja\n# # plt.scatter(group_13[:, 0], group_13[:, 1], s=20, marker='o', label=\"insert_AE\", color='#2ca02c')       # Verde\n# plt.scatter(group_21[:, 0], group_21[:, 1], s=20, marker='+', label=\"two_opt\", color='#1f77b4')   # Azul\n# plt.scatter(group_22[:, 0], group_22[:, 1], s=20, marker='+', label=\"swap\", color='#ff7f0e')       # Naranja\n# plt.scatter(group_23[:, 0], group_23[:, 1], s=20, marker='+', label=\"insert\", color='#2ca02c')       # Verde\n\n# # Limitar ejes:\n# plt.xlim(-6, 4)   # Cambia los valores según tu rango deseado en el eje x\n# plt.ylim(-5, 4)   # Cambia los valores según tu rango deseado en el eje y\n\n# plt.xlabel('x0', fontsize=12)\n# plt.ylabel('x1', fontsize=12)\n# plt.title(r'$\\mathit{NS_{ls}}$ instances over feature space', fontsize=14)\n# plt.legend(loc='best', frameon=True)\n# plt.grid(False)\n# plt.tight_layout()\n# plt.show()","metadata":{"id":"Hz8TA1iwTXqE","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.824875Z","iopub.status.idle":"2025-08-19T23:06:10.825325Z","shell.execute_reply.started":"2025-08-19T23:06:10.825108Z","shell.execute_reply":"2025-08-19T23:06:10.825127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.scatter(group_11[:, 0], group_11[:, 1], s=20, marker='o', label=\"two_opt_AE\", color='#1f77b4')   # Azul\n# plt.scatter(group_12[:, 0], group_12[:, 1], s=20, marker='o', label=\"swap_AE\", color='#ff7f0e')       # Naranja\n# plt.scatter(group_13[:, 0], group_13[:, 1], s=20, marker='o', label=\"insert_AE\", color='#2ca02c')       # Verde\n# # plt.scatter(group_21[:, 0], group_21[:, 1], s=20, marker='+', label=\"two_opt\", color='#1f77b4')   # Azul\n# # plt.scatter(group_22[:, 0], group_22[:, 1], s=20, marker='+', label=\"swap\", color='#ff7f0e')       # Naranja\n# # plt.scatter(group_23[:, 0], group_23[:, 1], s=20, marker='+', label=\"insert\", color='#2ca02c')       # Verde\n\n# # Limitar ejes:\n# plt.xlim(-6, 4)   # Cambia los valores según tu rango deseado en el eje x\n# plt.ylim(-5, 4)   # Cambia los valores según tu rango deseado en el eje y\n\n# plt.xlabel('x0', fontsize=12)\n# plt.ylabel('x1', fontsize=12)\n# plt.title(r'$\\mathit{NS_{ls}}$ instances over feature space', fontsize=14)\n# plt.legend(loc='best', frameon=True)\n# plt.grid(False)\n# plt.tight_layout()\n# plt.show()","metadata":{"id":"qaUNEWGTj1JN","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.826777Z","iopub.status.idle":"2025-08-19T23:06:10.827227Z","shell.execute_reply.started":"2025-08-19T23:06:10.827016Z","shell.execute_reply":"2025-08-19T23:06:10.827036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.scatter(group_11[:, 0], group_11[:, 1], s=20, marker='o', label=\"two_opt_AE\", color='#1f77b4')   # Azul\n# plt.scatter(group_12[:, 0], group_12[:, 1], s=20, marker='o', label=\"swap_AE\", color='#ff7f0e')       # Naranja\n# plt.scatter(group_13[:, 0], group_13[:, 1], s=20, marker='o', label=\"insert_AE\", color='#2ca02c')       # Verde\n# plt.scatter(group_21[:, 0], group_21[:, 1], s=20, marker='+', label=\"two_opt\", color='#1f77b4')   # Azul\n# plt.scatter(group_22[:, 0], group_22[:, 1], s=20, marker='+', label=\"swap\", color='#ff7f0e')       # Naranja\n# plt.scatter(group_23[:, 0], group_23[:, 1], s=20, marker='+', label=\"insert\", color='#2ca02c')       # Verde\n\n# # Limitar ejes:\n# plt.xlim(-6, 4)   # Cambia los valores según tu rango deseado en el eje x\n# plt.ylim(-5, 4)   # Cambia los valores según tu rango deseado en el eje y\n\n# plt.xlabel('x0', fontsize=12)\n# plt.ylabel('x1', fontsize=12)\n# plt.title(r'$\\mathit{NS_{ls}}$ instances over feature space', fontsize=14)\n# plt.legend(loc='best', frameon=True)\n# plt.grid(False)\n# plt.tight_layout()\n# plt.show()","metadata":{"id":"euhuWW2Ej1Qg","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.828986Z","iopub.status.idle":"2025-08-19T23:06:10.829512Z","shell.execute_reply.started":"2025-08-19T23:06:10.829269Z","shell.execute_reply":"2025-08-19T23:06:10.829290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # plt.scatter(group_11[:, 0], group_11[:, 1], s=20, marker='o', label=\"two_opt_AE\", color='#1f77b4')   # Azul\n# # plt.scatter(group_12[:, 0], group_12[:, 1], s=20, marker='o', label=\"swap_AE\", color='#ff7f0e')       # Naranja\n# # plt.scatter(group_13[:, 0], group_13[:, 1], s=20, marker='o', label=\"insert_AE\", color='#2ca02c')       # Verde\n# # plt.scatter(group_21[:, 0], group_21[:, 1], s=20, marker='+', label=\"two_opt\", color='#1f77b4')   # Azul\n# # plt.scatter(group_22[:, 0], group_22[:, 1], s=20, marker='+', label=\"swap\", color='#ff7f0e')       # Naranja\n# # plt.scatter(group_23[:, 0], group_23[:, 1], s=20, marker='+', label=\"insert\", color='#2ca02c')       # Verde\n# plt.scatter(group_3[:, 0], group_3[:, 1], s=20, marker='+', label=\"LOLIB\", color='#2ca02c')       # Verde\n\n# plt.xlabel('x0', fontsize=12)\n# plt.ylabel('x1', fontsize=12)\n# plt.title(r'$\\mathit{NS_{ls}}$ instances over feature space', fontsize=14)\n# plt.legend(loc='best', frameon=True)\n# plt.grid(False)\n# plt.tight_layout()\n# plt.show()","metadata":{"id":"hXlTB8rYs67i","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.830353Z","iopub.status.idle":"2025-08-19T23:06:10.830901Z","shell.execute_reply.started":"2025-08-19T23:06:10.830731Z","shell.execute_reply":"2025-08-19T23:06:10.830752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.scatter(group_11[:, 0], group_11[:, 1], s=20, marker='o', label=\"two_opt_AE\", color='#1f77b4')   # Azul\n# plt.scatter(group_12[:, 0], group_12[:, 1], s=20, marker='o', label=\"swap_AE\", color='#ff7f0e')       # Naranja\n# plt.scatter(group_13[:, 0], group_13[:, 1], s=20, marker='o', label=\"insert_AE\", color='#2ca02c')       # Verde\n# plt.scatter(group_21[:, 0], group_21[:, 1], s=20, marker='+', label=\"two_opt\", color='#1f77b4')   # Azul\n# plt.scatter(group_22[:, 0], group_22[:, 1], s=20, marker='+', label=\"swap\", color='#ff7f0e')       # Naranja\n# plt.scatter(group_23[:, 0], group_23[:, 1], s=20, marker='+', label=\"insert\", color='#2ca02c')       # Verde\n# plt.scatter(group_3[:, 0], group_3[:, 1], s=20, marker='+', label=\"LOLIB\", color='#2ca02c')       # Verde\n\n# plt.xlabel('x0', fontsize=12)\n# plt.ylabel('x1', fontsize=12)\n# plt.title(r'$\\mathit{NS_{ls}}$ instances over feature space', fontsize=14)\n# plt.legend(loc='best', frameon=True)\n# plt.grid(False)\n# plt.tight_layout()\n# plt.show()","metadata":{"id":"XrNiM_llswpr","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.831924Z","iopub.status.idle":"2025-08-19T23:06:10.832618Z","shell.execute_reply.started":"2025-08-19T23:06:10.832187Z","shell.execute_reply":"2025-08-19T23:06:10.832212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.cluster import KMeans\n\n# n_clusters = 3\n# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n# labels = kmeans.fit_predict(matrix)\n\n# num_zeros = (labels == 1).sum()\n# print(num_zeros)\n","metadata":{"id":"-pfuOP3HocaE","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.836346Z","iopub.status.idle":"2025-08-19T23:06:10.837840Z","shell.execute_reply.started":"2025-08-19T23:06:10.836740Z","shell.execute_reply":"2025-08-19T23:06:10.836763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install --upgrade --force-reinstall scikit-learn-extra","metadata":{"id":"C63Lskzewu6s","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.839948Z","iopub.status.idle":"2025-08-19T23:06:10.840476Z","shell.execute_reply.started":"2025-08-19T23:06:10.840272Z","shell.execute_reply":"2025-08-19T23:06:10.840294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn_extra.cluster import KMedoids\n# from sklearn.metrics import pairwise_distances\n\n# kmedoids = KMedoids(n_clusters=3, metric='manhattan', random_state=42)\n# labels = kmedoids.fit_predict(matrix)\n\n# num_zeros = (labels == 0).sum()\n# print(num_zeros)\n\n","metadata":{"id":"7danwfkutiqc","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.841968Z","iopub.status.idle":"2025-08-19T23:06:10.842348Z","shell.execute_reply.started":"2025-08-19T23:06:10.842161Z","shell.execute_reply":"2025-08-19T23:06:10.842175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# # reduced_matrix: datos reducidos a 2D usando PCA\n# # labels: resultado de kmeans.fit_predict(...)\n\n# plt.figure(figsize=(8, 6))\n\n# Puntos coloreados por su cluster\n# plt.scatter(reduced_data[:, 0], reduced_data[:, 1],\n#             c=labels, cmap='viridis', s=50)\n\n# plt.title('Clusters visualizados en 2D con PCA')\n# plt.xlabel('Componente Principal 1')\n# plt.ylabel('Componente Principal 2')\n# plt.grid(True)\n# plt.show()\n","metadata":{"id":"674MrKnCpJuf","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.844568Z","iopub.status.idle":"2025-08-19T23:06:10.844963Z","shell.execute_reply.started":"2025-08-19T23:06:10.844794Z","shell.execute_reply":"2025-08-19T23:06:10.844809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# set_global_seed(42)\n# set_global_seed_2(42)\n\n# class Autoencoder(nn.Module):\n#     def __init__(self, input_dim, latent_dim, hidden_dim=50):\n#         super(Autoencoder, self).__init__()\n\n#         self.encoder = nn.Sequential(\n#             nn.Linear(input_dim, hidden_dim),\n#             nn.ReLU(),\n#             nn.Linear(hidden_dim, latent_dim)\n#         )\n\n#         self.decoder = nn.Sequential(\n#             nn.Linear(latent_dim, hidden_dim),\n#             nn.ReLU(),\n#             nn.Linear(hidden_dim, input_dim),\n#             nn.Tanh()\n#         )\n\n#     def forward(self, x):\n#         z = self.encoder(x)\n#         out = self.decoder(z)\n#         return out\n\n# def ae_loss(recon_x, x):\n#     return F.mse_loss(recon_x, x, reduction='sum')\n\n# def train_autoencoder(model, data, epochs=50, batch_size=64, lr=1e-3):\n#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n#     for epoch in range(epochs):\n#         model.train()\n#         total_loss = 0\n#         for i in range(0, len(data), batch_size):\n#             batch = data[i:i+batch_size]\n#             optimizer.zero_grad()\n#             recon = model(batch)\n#             loss = ae_loss(recon, batch)\n#             loss.backward()\n#             optimizer.step()\n#             total_loss += loss.item()\n#         # print(f'Epoch {epoch+1}, Loss: {total_loss / len(data):.4f}')\n\n# def get_ae_latents(model, data, batch_size=64):\n#     model.eval()\n#     latents = []\n#     with torch.no_grad():\n#         for i in range(0, len(data), batch_size):\n#             batch = data[i:i+batch_size]\n#             z = model.encoder(batch)\n#             latents.append(z)\n#     return torch.cat(latents, dim=0)\n\n# matrix = np.vstack((data_1, data_2, data_3))\n# flat_data = matrix.reshape(matrix.shape[0], -1)\n# data = torch.tensor(flat_data, dtype=torch.float32)\n\n\n# input_dim = data.shape[1]\n# latent_dim = 2\n\n\n# ae_model_graph = Autoencoder(input_dim=input_dim, latent_dim=latent_dim)\n\n\n# train_autoencoder(ae_model_graph, data, epochs=50, batch_size=64)\n\n\n# z = get_ae_latents(ae_model_graph, data, 64)\n# print(z.shape)  # (num_instancias, latent_dim)\n\n# group_1 = z[0:size_11, :]\n# group_2 = z[size_11:size_11+size_22, :]\n# group_3 = z[size_11+size_22:, :]\n# # group_4 = z[size_11+size_22+size_33:, :]","metadata":{"id":"ocES5ss3UTXi","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.846791Z","iopub.status.idle":"2025-08-19T23:06:10.847621Z","shell.execute_reply.started":"2025-08-19T23:06:10.847352Z","shell.execute_reply":"2025-08-19T23:06:10.847376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.figure(figsize=(8, 6))\n# plt.scatter(group_1[:, 0], group_1[:, 1], label=\"Grupo 1\", alpha=0.7)\n# plt.scatter(group_2[:, 0], group_2[:, 1], label=\"Grupo 2\", alpha=0.7)\n# plt.scatter(group_3[:, 0], group_3[:, 1], label=\"Grupo 3\", alpha=0.7)\n# # plt.scatter(group_4[:, 0], group_4[:, 1], label=\"Grupo 4\", alpha=0.7)\n\n# plt.title(\"Espacio Latente (Autoencoder)\")\n# plt.xlabel(\"Latente 1\")\n# plt.ylabel(\"Latente 2\")\n# plt.legend()\n# plt.grid(True)\n# plt.tight_layout()\n# plt.show()","metadata":{"id":"rSolfIrjUkmr","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.848315Z","iopub.status.idle":"2025-08-19T23:06:10.848754Z","shell.execute_reply.started":"2025-08-19T23:06:10.848547Z","shell.execute_reply":"2025-08-19T23:06:10.848565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# z_np = z.detach().cpu().numpy()\n# labels_np = labels.numpy() if isinstance(labels, torch.Tensor) else np.array(labels)","metadata":{"id":"GwfiS58xrPkd","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.849811Z","iopub.status.idle":"2025-08-19T23:06:10.850230Z","shell.execute_reply.started":"2025-08-19T23:06:10.850045Z","shell.execute_reply":"2025-08-19T23:06:10.850065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# plt.figure(figsize=(8, 6))\n\n# scatter = plt.scatter(z_np[:, 0], z_np[:, 1], c=labels_np, cmap='viridis', s=50)\n# plt.colorbar(scatter, label='Clusters / Labels')\n\n# plt.title('Latentes del Autoencoder con Labels')\n# plt.xlabel('Latente 1')\n# plt.ylabel('Latente 2')\n# plt.grid(True)\n# plt.show()\n","metadata":{"id":"smUEEF6CrRWQ","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.852957Z","iopub.status.idle":"2025-08-19T23:06:10.853631Z","shell.execute_reply.started":"2025-08-19T23:06:10.853291Z","shell.execute_reply":"2025-08-19T23:06:10.853318Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"En vez de usar K-means (No supervisado), voy a intentar hacer un modelo de clasificacion supervisada, usando el rendom forest","metadata":{"id":"jXKUEvh1h8ME"}},{"cell_type":"markdown","source":"Distribucion empirica","metadata":{"id":"i7Ms5MSmY6BY"}},{"cell_type":"code","source":"# instancias_insert = np.load('instancias_insert.npy')\n# instancias_swap = np.load('instancias_swap.npy')\n# instancias_two_opt = np.load('instancias_two_opt.npy')\n# len_insert = instancias_insert.shape[0]\n# len_swap = instancias_swap.shape[0]\n# len_two_opt = instancias_two_opt.shape[0]\n# poblacion_desc = np.concatenate((instancias_two_opt, instancias_insert, instancias_swap), axis=0)\n# print(len_insert)\n# print(len_swap)\n# print(len_two_opt)\n# print(poblacion_desc.shape)","metadata":{"id":"iQ0LSURYbgP9","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.855106Z","iopub.status.idle":"2025-08-19T23:06:10.855655Z","shell.execute_reply.started":"2025-08-19T23:06:10.855477Z","shell.execute_reply":"2025-08-19T23:06:10.855495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n\n# def valores_sin_diagonal(entrenamiento):\n#     # entrenamiento: array 3D (n_matrices, N, N)\n#     n_matrices, N, _ = entrenamiento.shape\n\n#     # Creamos una máscara para valores no diagonales\n#     mask = np.ones((N, N), dtype=bool)\n#     np.fill_diagonal(mask, False)\n\n#     # Extraemos valores no diagonales de cada matriz y aplanamos\n#     valores = entrenamiento[:, mask].flatten()\n#     return valores\n","metadata":{"id":"7f4bxzHxggj3","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.858286Z","iopub.status.idle":"2025-08-19T23:06:10.858764Z","shell.execute_reply.started":"2025-08-19T23:06:10.858550Z","shell.execute_reply":"2025-08-19T23:06:10.858568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"0.4988-0.4644","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:06:10.860669Z","iopub.status.idle":"2025-08-19T23:06:10.861193Z","shell.execute_reply.started":"2025-08-19T23:06:10.860911Z","shell.execute_reply":"2025-08-19T23:06:10.860930Z"}},"outputs":[],"execution_count":null}]}